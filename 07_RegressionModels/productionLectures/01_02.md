---
title       : Regression through the origin
subtitle    : Regression
author      : Brian Caffo, PhD
job         : Johns Hopkins Bloomberg School of Public Health
logo        : bloomberg_shield.png
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
url:
  lib: ../../libraries
  assets: ../../assets
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---

## Regression through the origin

* Consider the following problem: you have several $(X_i, Y_i)$ pairs and you want to find the best line running through the origin.
* A line through the origin would be of the form $Y = \beta_1 X$.
* Least squares would find the $\beta_1$ that minimizes
$$
\sum_{i=1}^n (Y_i - \beta_1 X_i)^2.
$$
* The solution, as it turns out, is
$$
\hat \beta_1 = \frac{\sum_{i=1^n} Y_i X_i}{\sum_{i=1}^n X_i^2}.
$$

---
## Showing it

$$
\sum_{i=1}^n (Y_i - \beta_1 X_i)^2
= \sum_{i=1}^n (Y_i - \hat \beta_1 X_i + \hat \beta_1 X_i - \beta_1 X_i)^2
$$


$$
= \sum_{i=1}^n (Y_i - \hat \beta_1 X_i)^2 + 2 \sum_{i=1}^n (Y_i - \hat \beta_1 X_i)(\hat \beta_1 X_i - \beta_1 X_i) + \sum_{i=1}^n (\hat \beta_1 X_i - \beta_1 X_i)^2
$$

$$
\dagger \geq \sum_{i=1}^n (Y_i - \hat \beta_1 X_i)^2 + 2 (\hat \beta_1 - \beta_1) \sum_{i=1}^n (Y_i X_i - \hat \beta_1 X_i^2) 
$$

$$
\sum_{i=1}^n (Y_i X_i - \hat \beta_1 X_i^2) = \sum_{i=1}^n Y_i X_i - \hat \beta_1 \sum_{i=1}^n X_i^2 = 0
$$

So that

$$
\dagger \geq \sum_{i=1}^n (Y_i - \hat \beta_1 X_i)^2 
$$
